---
title: "Creative Component"
author: "Taikgun Song"
header-includes:
   - \usepackage{graphicx}
   - \usepackage{bbm}
   - \usepackage{titlesec}
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
geometry: margin=1in
bibliography: refs.bib
---
```{r hidecode, echo=FALSE}
library(knitr)
opts_chunk$set(echo=FALSE, warning=FALSE, message = FALSE, tidy.opts=list(width.cutoff=40))

```

```{r libraries, message=FALSE, warning=FALSE, error=FALSE}
# Load Libraries
require(openNLP)
require(NLP)
require(topicmodels)
require(tm)
require(MultinomialCI)
library(RTextTools)
library(SnowballC)

```


The Trip Advisor reviews are scrapped and read into `R` [@R] using the `RCurl` [@RCurl] package. Then the following `R` packages were utilized to conduct `Latent Dirichlet Allocation`[@blei2003latent] method: `openNLP`[@openNLP], `NLP` [@NLP], `topicmodels` [@topicmodels], `tm` [@tm], `RTextTools` [@RTextTools], and `SnowballC` [@SnowballC] packages.

# September 9, 2016

1. Last Meeting
* Setting up a GitHub repository. https://github.com/jeffsong9/creative
* Upload data file
*	Xkcd
* Run LDA with different n-grams

1. This week
* Built a desktop PC
* Installed Linux
* Parsey McParseface
- Google Blog: https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html
- Github: https://github.com/tensorflow/models/tree/master/syntaxnet


# September 16, 2016

1. Last meeting

* List of stop words for English.
* Stemming
* What are k-grams? Try {1, 2, 3}-grams
* Change number of topics for LDA
* Document above in steps.
* Read LDA paper by Blei.
* Track R packages


2. This week

1) Stop words.
"Stop words" are words frequently used in language, but with insignificant meanings.  For example, POS such as articles or preposition is a good example of "stop words".  Since LDA method estimates parameters in the model based on observed documents, meaningless ¡°stop words¡± should be filtered out before applying text mining techniques.  List of ¡°stop words¡± in R package `tm` was used.

e.g.
```{r}
#dtm <- DocumentTermMatrix(vdc,control=list(stopwords=T))
print("dtm <- DocumentTermMatrix(vdc,control=list(stopwords=T))")
```



`tm` has different list of ¡°stop words¡±, therefore I need to find out which one works the best for our research. The list could be selected by changing the ¡°kind¡± variable.

e.g.
```{r}
#stopwords(kind = ¡°en¡±), stopwords(kind = ¡°SMART¡±)
print("stopwords(kind = ¡°en¡±), stopwords(kind = ¡°SMART¡±)")
```




2) Stemming
Stemming is the process of reducing inflected words to their word stem, base or root form.  Since words with the same stem could be written in different POS, we could reduce the word dimension of a corpus by stemming with minimal loss of information.  ¡°stemDocument¡± function in ¡°tm¡± package will be used.

e.g.
```{r}
#stemDocument(vdc[[1]])
print("stemDocument(vdc[[1]])")
```


3. Next Week
1) Read and summarize `Latent Dirichlet Allocation`[@blei2003latent] by Blei, Ng, and Jordan.
2) Get familiar with the ¡°tm¡± package by running toy dataset.
	Q: Is there any way that I could see the function written in packages? I have tried ¡°?LDA¡±
	Q2: Any suggestion on how to compare different methods? E.g. Two way table?

```{r some-code, ref.label=all_labels()[-1], echo=FALSE, eval=FALSE}
```

$\pagebreak$

#References