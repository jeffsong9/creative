pkg=c("tidytext","tidyverse", "pander","topicmodels", "tm", "gridExtra", "pipeR", "ggtern", "tidyr")
sapply(pkg, require, character=T)
'%!in%' <- function(x,y)!('%in%'(x,y))
source("req.R")
dat=rbind.data.frame(
readRDS("../data/twitter_inlove.Rds") %>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "inlove"),
readRDS("../data/twitter_hateher.Rds")%>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "hateher"),
readRDS("../data/twitter_marchscience.Rds") %>%.$V1 %>% paste0(collapse=" "),
stringsAsFactors = F
# mutate(tag = "marchscience"), stringsAsFactors = F
)
names(dat)<-"V1"
dat$V1 %>>%
tolower() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()-> dat1
stop_stem=lapply(dat1, StopNStem) %>%
do.call("rbind",.) %>%
rbind.data.frame(stringsAsFactors=F)
stop_stem$V1 %>%
VectorSource() %>%
VCorpus()%>%
DocumentTermMatrix() ->dtm
lda=LDA(dtm, k = 3, control = list(alpha=1))
lda.raw=terms(lda,10)
ap_topics <- tidy(lda, matrix = "beta")
names(ap_topics)[3]<-"phi"
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, phi) %>%
ungroup() %>%
arrange(topic, desc(phi)) #%>%View()
ap_top_terms %>%
mutate(order = row_number())->ap_top_terms2
ap_topics %>%
group_by(term) %>%
mutate(sum_prob=sum(phi)) %>%
mutate(per_word_per_topic=phi/sum_prob) %>%
ungroup()->ap_per_word_per_topic
View(ap_per_word_per_topic)
ap_per_word_per_topic %>%
select(topic, term, per_word_per_topic) %>%
spread(topic, per_word_per_topic)->plot_this
plot_this %>%
filter(term %in% {ap_top_terms$term %>% unique()})->use_this
ggtern(data=use_this, aes(x = `1`, y = `2`, z = `3`)) +
# geom_point(aes(fill = term),size = 3,shape = 21)+
# ggtitle(“LDA RAW”) +
theme_rgbw() +
theme(legend.position = c(0,1),legend.justification = c(1, 1))+
geom_text(data=use_this, aes(x = `1`, y = `2`, z = `3`, label=term))
dat$V1 %>>%
tolower() %>>%
cleaning_u_plus() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()->dat2
dat$V1 %>>%
tolower() %>>%
cleaning_u_plus() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()->dat2
stop_stem=lapply(dat2, StopNStem) %>%
do.call("rbind",.) %>%
rbind.data.frame(stringsAsFactors=F)
stop_stem %>%
VectorSource() %>%
VCorpus()%>%
DocumentTermMatrix() ->dtm
lda=LDA(dtm,k = 3, control = list(alpha=1))
lda.no_uni=terms(lda,5)
ap_topics <- tidy(lda, matrix = "beta")
names(ap_topics)[3]<-"phi"
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, phi) %>%
ungroup() %>%
arrange(topic, desc(phi)) #%>% View()
ap_top_terms %>%
mutate(order = row_number())->ap_top_terms2
ap_topics %>%
group_by(term) %>%
mutate(sum_prob=sum(phi)) %>%
mutate(per_word_per_topic=phi/sum_prob) %>%
ungroup()->ap_per_word_per_topic
# saveRDS(ap_per_word_per_topic, "ap_per_word_per_topic.rds")
# readRDS("ap_per_word_per_topic.rds")->ap_per_word_per_topic
ap_per_word_per_topic %>%
select(topic, term, per_word_per_topic) %>%
spread(topic, per_word_per_topic)->plot_this
# plot_this[complete.cases(plot_this), ]->plot_this
# plot_this$`1`<-as.numeric(plot_this$`1`)
# plot_this$`2`<-as.numeric(plot_this$`2`)
# plot_this$`3`<-as.numeric(plot_this$`3`)
plot_this %>%
filter(term %in% {ap_top_terms$term %>% unique()})->use_this
ggtern(data=use_this, aes(x = `1`, y = `2`, z = `3`)) +
# geom_point(aes(fill = term),size = 3,shape = 21)+
# ggtitle(“LDA RAW”) +
theme_rgbw() +
theme(legend.position = c(0,1),legend.justification = c(1, 1))+
geom_text(data=use_this, aes(x = `1`, y = `2`, label=term))
emoji_simple=read.csv("../data/all_emoji.csv", stringsAsFactors = F)
# emoji_simple$unicode<-gsub("[[:punct:]]", "", emoji_simple$unicode)
U_to_N=function(word){
emoji_simple %>%
filter(unicode==word)->see_trans
if(length(see_trans$trans)==0){
return(word)
}else{
return(see_trans$trans)
}
}
check7=NULL
for(j in 1:length(dat$V1)){
string=dat$V1[j] %>% tolower()
words=strsplit(string, " ")
words=words[[1]]
translated=""
for(i in 1:length(words)){
translated=paste(translated, U_to_N(words[i]), collapse = " ")
# print(paste0(j,"-", i))
}
check7=rbind(check7, translated)
# print(j)
}
check7 %>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()-> check7
# cbind.data.frame(dat, check7, stringsAsFactors=F)->check8
# names(check8)<-c("raw_string", "emoji_present", "string_translated")
# saveRDS(check8, "../Data/twitter_all.Rds")
stop_stem=lapply(check7, StopNStem) %>%
do.call("rbind",.) %>%
rbind.data.frame(stringsAsFactors=F)
stop_stem %>%
VectorSource() %>%
VCorpus()%>%
DocumentTermMatrix() ->dtm
lda=LDA(dtm, k = 3, control = list(alpha=1))
lda.t=terms(lda,5)
