sapply(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis))), function(x)emojidata$uni_png[[x]])
test<-lapply(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis))), function(x)emojidata$uni_png[[x]])
test
tern_plot_no_text+
annotation_raster_tern(test[[1]], xmin = 0.3, xmax = .4, ymin = 0.7, ymax =0.8,
interpolate = FALSE)
test<-emojidata$uni_png[[which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis[1])))]]
tern_plot_no_text+
annotation_raster_tern(test[[1]], xmin = 0.3, xmax = .4, ymin = 0.7, ymax =0.8,
interpolate = FALSE)
test<-emojidata$uni_png[[which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis[1])))]]
crd=coord_tern()
test2<-as.data.frame(use_this[22,])
names(test2)<-c("term", "x", "y", "z")
test2 %>%
select(-term) %>%
tlr2xy(crd)
tern_plot_no_text+
annotation_raster_tern(test, xmin = 0.3, xmax = .4, ymin = 0.7, ymax =0.8,
interpolate = FALSE)
source("req.R")
Sys.setlocale('LC_ALL','C')
load("../data/emojidata.rda")
twitter_example_inlove=readRDS("../data/twitter_inlove.Rds")
twitter_example_hateher=readRDS("../data/twitter_hateher.Rds")
twitter_example_marchscience=readRDS("../data/twitter_marchscience.Rds")
prop_emoji=cbind.data.frame(498/944, 335/1145, 93/1195)
colnames(prop_emoji)<-c("#inlove", "#hateher", "#marchscience")
rownames(prop_emoji)<-"Proportion"
pander(prop_emoji, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:EProp} Proportion of Twitter messages with emoji")
filter(twitter_example_inlove, grepl("U\\+",V1)) %>%
unnest_tokens(word, V1, token = "regex", pattern = "[\\s]") %>%
select(word) %>%
filter(grepl("u\\+",word)) %>%
count(word, sort = TRUE) %>%
head(5)->inlove_uni_count
colnames(inlove_uni_count)<-c("#inlove","Count")
filter(twitter_example_hateher, grepl("U\\+",V1)) %>%
unnest_tokens(word, V1, token = "regex", pattern = "[\\s]") %>%
select(word) %>%
filter(grepl("u\\+",word)) %>%
count(word, sort = TRUE) %>%
head(5)->hateher_uni_count
colnames(hateher_uni_count)<-c("#hateher","Count")
filter(twitter_example_marchscience, grepl("U\\+",V1)) %>%
unnest_tokens(word, V1, token = "regex", pattern = "[\\s]") %>%
select(word) %>%
filter(grepl("u\\+",word)) %>%
count(word, sort = TRUE) %>%
head(5)->marchscience_uni_count
colnames(marchscience_uni_count)<-c("#marchscience","Count")
emoji_freq=cbind.data.frame(inlove_uni_count, hateher_uni_count, marchscience_uni_count)
pander(emoji_freq, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:EPopular} Five most popular emoji for each hastags")
# xdate_number=xtable(emoji_freq, caption = "Five most popular emoji for each hastags", label = "tab:EPopular")
# print(xdate_number)
# dat=rbind.data.frame(
#   readRDS("../Data/twitter_inlove.Rds") %>%
#     mutate(tag = "inlove"),
#   readRDS("../Data/twitter_hateher.Rds")%>%
#     mutate(tag = "hateher"),
#   readRDS("../data/twitter_marchscience.Rds") %>%
#     mutate(tag = "marchscience"), stringsAsFactors = F
#   )
dat=rbind.data.frame(
readRDS("../data/twitter_inlove.Rds") %>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "inlove"),
readRDS("../data/twitter_hateher.Rds")%>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "hateher"),
readRDS("../data/twitter_marchscience.Rds") %>%.$V1 %>% paste0(collapse=" "),
stringsAsFactors = F
# mutate(tag = "marchscience"), stringsAsFactors = F
)
names(dat)<-"V1"
dat$V1 %>>%
tolower() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()-> dat1
stop_stem=lapply(dat1, StopNStem) %>%
do.call("rbind",.) %>%
rbind.data.frame(stringsAsFactors=F)
stop_stem$V1 %>%
VectorSource() %>%
VCorpus()%>%
DocumentTermMatrix() ->dtm
lda=LDA(dtm, k = 3, control = list(alpha=1))
lda.raw=terms(lda,10)
pander(lda.raw, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:LDAraw} Output LDA with the raw data")
ap_topics <- tidy(lda, matrix = "beta")
names(ap_topics)[3]<-"phi"
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, phi) %>%
ungroup() %>%
arrange(topic, desc(phi)) #%>%View()
# ap_top_terms<-ap_top_terms[-11,] #Two topic 1 with same phi
split(ap_top_terms, as.factor(ap_top_terms$topic)) %>%
do.call("cbind",.) %>%
select(everything(), -contains("topic")) %>%
pander(split.table = 180, style = 'rmarkdown', caption = "\\label{tab:LDArawp} Word prob. given topic")
# plot_ea_topic=function(topic_number, y_lim){
# ap_top_terms %>%
#   filter(topic==topic_number) %>%
#   mutate(term = reorder(term, phi)) %>%
#   ggplot(aes(term, phi))+
#   geom_bar(stat = "identity") +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))+
#   ylab(expression(phi))+
#   ylim(0, y_lim)
# }
# lapply(1:3, function(x) plot_ea_topic(x, 0.1))-> plot_raw
# grid.arrange(plot_raw[[1]], plot_raw[[2]], plot_raw[[3]], nrow=1)#,layout_matrix=cbind(1,2,3))
ap_top_terms %>%
mutate(order = row_number())->ap_top_terms2
ap_top_terms2 %>>%
ggplot(aes(x = order, y = phi))+
geom_bar(stat='identity', na.rm=T)+
# facet_grid(~topic, scales = "free", space = "free") +
facet_wrap(~topic, scales = "free") +
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
ylab(expression(phi))+
scale_x_continuous(breaks = ap_top_terms2$order, labels = ap_top_terms2$term, expand = c(0,0))
ap_topics %>%
group_by(term) %>%
mutate(sum_prob=sum(phi)) %>%
mutate(per_word_per_topic=phi/sum_prob) %>%
ungroup()->ap_per_word_per_topic
# saveRDS(ap_per_word_per_topic, "ap_per_word_per_topic.rds")
# readRDS("ap_per_word_per_topic.rds")->ap_per_word_per_topic
ap_per_word_per_topic %>%
select(topic, term, per_word_per_topic) %>%
spread(topic, per_word_per_topic)->plot_this
# plot_this[complete.cases(plot_this), ]->plot_this
# plot_this$`1`<-as.numeric(plot_this$`1`)
# plot_this$`2`<-as.numeric(plot_this$`2`)
# plot_this$`3`<-as.numeric(plot_this$`3`)
plot_this %>%
filter(term %in% {ap_top_terms$term %>% unique()})->use_this
ggtern(data=use_this, aes(x = `1`, y = `2`, z = `3`)) +
geom_point(aes(fill = term),size = 3,shape = 21)+
# ggtitle(“LDA RAW”) +
theme_rgbw() +
theme(legend.position = c(0,1),legend.justification = c(1, 1))+
geom_text(data=use_this, aes(x = `1`, y = `2`, label=term))->tern_plot_text#, z = `3`, label=term))
ggtern(data=use_this, aes(x = `1`, y = `2`, z = `3`)) +
geom_point(aes(),size = 3,shape = 21)+
# geom_point(aes(fill = term),size = 3,shape = 21)+
# ggtitle(“LDA RAW”) +
theme_rgbw() +
theme(legend.position = c(0,1),legend.justification = c(1, 1))->tern_plot_no_text
crd=coord_tern()
emojis=use_this[grepl("^u[[:alnum:]]{4,5}$", use_this$term),] %>% as.data.frame(stringsAsFactors=F)
names(emojis)<-c("term", "x", "y", "z")
emojis %>%
select(-term) %>%
tlr2xy(crd) %>%
cbind.data.frame(emojis,.) %>%
.[,c(1,5,6)]->emojis
test<-emojidata$uni_png[[min(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis$term[2]))))]]
save_raster_tern<-tern_plot_no_text
for(i in 1:nrow(emojis)){
save_raster_tern+
emojidata$uni_png[[min(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis$term[i]))))]] %>%
annotation_raster_tern(
xmin =floor(emojis$x[i]*10)/10,
xmax =ceiling(emojis$x[i]*10)/10,
ymin =floor(emojis$y[i]*10)/10,
ymax = ceiling(emojis$y[i]*10)/10,
interpolate = FALSE)->save_raster_tern
}
save_raster_tern
# tern_plot_no_text+
#   annotation_raster_tern(test, xmin = 0.3, xmax = .4, ymin = 0.7, ymax =0.8,
# interpolate = FALSE)
use_this2<-as.data.frame(use_this)
names(use_this2)<-c("term", "x", "y", "z")
# g<-rasterGrob(test, interpolate = T)
# use_this2%>%
#   select(-term) %>%
#   tlr2xy(crd)%>%
#   cbind(use_this) %>%
#   ggplot(aes(x=x, y=y))+
#   geom_point()+
#   annotation_custom(g, xmin = 0.4, xmax = 0.5, ymin = 0.7, ymax = 0.8)+
#   theme(aspect.ratio = 0.9)
save_annotation_custom=use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this) %>%
ggplot(aes(x=x, y=y))+
geom_point(aes(x=x, y=y), color = 'red') +
geom_text_repel(aes(x=x, y=y, label = term), direction = "x")+
theme(aspect.ratio = 0.9)
install.packages("ggrepel")
pkg=c("tidytext","tidyverse", "pander","topicmodels", "tm", "gridExtra", "pipeR", "ggtern", "tidyr", "png", "grid", "ggrepel")
sapply(pkg, require, character=T)
save_annotation_custom=use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this) %>%
ggplot(aes(x=x, y=y))+
geom_point(aes(x=x, y=y), color = 'red') +
geom_text_repel(aes(x=x, y=y, label = term), direction = "x")+
theme(aspect.ratio = 0.9)
for(i in 1:nrow(emojis)){
save_annotation_custom+
emojidata$uni_png[[min(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis$term[i]))))]] %>%
rasterGrob(interpolate = T) %>%
annotation_custom(
xmin =floor(emojis$x[i]*10)/10,
xmax =ceiling(emojis$x[i]*10)/10,
ymin =floor(emojis$y[i]*10)/10,
ymax = ceiling(emojis$y[i]*10)/10)->save_annotation_custom
}
save_annotation_custom
save_annotation_custom=use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this) %>%
ggplot(aes(x=x, y=y))+
geom_point(aes(x=x, y=y), color = 'red') +
geom_text(aes(x=x, y=y, label = term))+
theme(aspect.ratio = 0.9)
for(i in 1:nrow(emojis)){
save_annotation_custom+
emojidata$uni_png[[min(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis$term[i]))))]] %>%
rasterGrob(interpolate = T) %>%
annotation_custom(
xmin =floor(emojis$x[i]*10)/10,
xmax =ceiling(emojis$x[i]*10)/10,
ymin =floor(emojis$y[i]*10)/10,
ymax = ceiling(emojis$y[i]*10)/10)->save_annotation_custom
}
save_annotation_custom
save_annotation_custom=use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this) %>%
ggplot(aes(x=x, y=y))+
geom_point(aes(x=x, y=y), color = 'red') +
geom_text_repel(aes(x=x, y=y, label = term), direction = "x")+
theme(aspect.ratio = 0.9)
for(i in 1:nrow(emojis)){
save_annotation_custom+
emojidata$uni_png[[min(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis$term[i]))))]] %>%
rasterGrob(interpolate = T) %>%
annotation_custom(
xmin =floor(emojis$x[i]*10)/10,
xmax =ceiling(emojis$x[i]*10)/10,
ymin =floor(emojis$y[i]*10)/10,
ymax = ceiling(emojis$y[i]*10)/10)->save_annotation_custom
}
save_annotation_custom
save_annotation_custom=use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this) %>%
ggplot(aes(x=x, y=y))+
geom_point(aes(x=x, y=y), color = 'red') +
geom_text_repel(aes(x=x, y=y, label = term))+
theme(aspect.ratio = 0.9)
for(i in 1:nrow(emojis)){
save_annotation_custom+
emojidata$uni_png[[min(which(emojidata$uni_code %in% gsub("U","U+",toupper(emojis$term[i]))))]] %>%
rasterGrob(interpolate = T) %>%
annotation_custom(
xmin =floor(emojis$x[i]*10)/10,
xmax =ceiling(emojis$x[i]*10)/10,
ymin =floor(emojis$y[i]*10)/10,
ymax = ceiling(emojis$y[i]*10)/10)->save_annotation_custom
}
save_annotation_custom
tri=c(x=c(0, 0.5, 1), y=c(0, 1, 0))
qplot(tri, x, y)
qplot(data, tri, x, y)
qplot(data=tri, x, y)
tri=data.frame(x=c(0, 0.5, 1), y=c(0, 1, 0))
tri
tri=data.frame(x=c(0, 0.5, 1), y=c(0, 1, 0))
qplot(data=tri, x, y)
qplot(data=tri, x, y)+
geom_path()
tri=data.frame(x=c(0, 0.5, 1, 0), y=c(0, 1, 0, 0))
save_annotation_custom
qplot(data=tri, x, y)+
geom_path()
save_annotation_custom+
qplot(data=tri, x, y)+
geom_path()
save_annotation_custom+
qplot(data=tri, aes(x=x, y=y))+
geom_path()
qplot(data=tri, aes(x=x, y=y))+
geom_path()
qplot(data=tri, x, y)+
geom_path()
save_annotation_custom+
ggplot(data=tri, x, y)+
geom_path()
ggplot(data=tri, x, y)+
geom_path()
ggplot(data=tri, aes(x, y))+
geom_path()
save_annotation_custom+
ggplot(data=tri, aes(x, y))+
geom_path()
use_this2
use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this)
tri
save_annotation_custom
tri=list(x=c(0, 0.5, 1, 0), y=c(0, 1, 0, 0))
save_annotation_custom+
ggplot(data=tri, aes(x, y))+
geom_path()
custom=use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this)
use_this2%>%
select(-term) %>%
tlr2xy(crd)%>%
cbind(use_this)
tri=data.frame(x=c(0, 0.5, 1, 0), y=c(0, 1, 0, 0), term=NULL, `1`=NULL, `2`= NULL, `3`=NULL)
tri=data.frame(x=c(0, 0.5, 1, 0), y=c(0, 1, 0, 0), term=NA, `1`=NA, `2`=NA, `3`=NA)
save_annotation_custom+
ggplot(data=tri, aes(x, y))+
geom_path()
ggplot(data=tri, aes(x, y))+
geom_path()
ggplot(data=tri, aes(x, y))+
geom_path(aes(x, y))
save_annotation_custom+
ggplot(data=tri, aes(x, y))+
geom_path(aes(x, y))
ggplot()+
save_annotation_custom+
ggplot()+
geom_path(data=triaes(x, y))
ggplot()+
geom_path(data=triaes(x, y))
ggplot()+
geom_path(data=tri, aes(x, y))
save_annotation_custom+
ggplot()+
geom_path(data=tri, aes(x, y))
save_annotation_custom+
geom_path(data=tri, aes(x, y))
tri=data.frame(x=c(0, 0.5, 1, 0), y=c(0, 1, 0, 0))
save_annotation_custom+
geom_path(data=tri, aes(x, y))
use_this2<-as.data.frame(use_this)
names(use_this2)<-c("term", "x", "y", "z")
source("req.R")
library(ggrepel)
Sys.setlocale('LC_ALL','C')
load("../data/emojidata.rda")
twitter_example_inlove=readRDS("../data/twitter_inlove.Rds")
twitter_example_hateher=readRDS("../data/twitter_hateher.Rds")
twitter_example_marchscience=readRDS("../data/twitter_marchscience.Rds")
prop_emoji=cbind.data.frame(498/944, 335/1145, 93/1195)
colnames(prop_emoji)<-c("#inlove", "#hateher", "#marchscience")
rownames(prop_emoji)<-"Proportion"
pander(prop_emoji, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:EProp} Proportion of Twitter messages with emoji")
filter(twitter_example_inlove, grepl("U\\+",V1)) %>%
unnest_tokens(word, V1, token = "regex", pattern = "[\\s]") %>%
select(word) %>%
filter(grepl("u\\+",word)) %>%
count(word, sort = TRUE) %>%
head(5)->inlove_uni_count
colnames(inlove_uni_count)<-c("#inlove","Count")
filter(twitter_example_hateher, grepl("U\\+",V1)) %>%
unnest_tokens(word, V1, token = "regex", pattern = "[\\s]") %>%
select(word) %>%
filter(grepl("u\\+",word)) %>%
count(word, sort = TRUE) %>%
head(5)->hateher_uni_count
colnames(hateher_uni_count)<-c("#hateher","Count")
filter(twitter_example_marchscience, grepl("U\\+",V1)) %>%
unnest_tokens(word, V1, token = "regex", pattern = "[\\s]") %>%
select(word) %>%
filter(grepl("u\\+",word)) %>%
count(word, sort = TRUE) %>%
head(5)->marchscience_uni_count
colnames(marchscience_uni_count)<-c("#marchscience","Count")
emoji_freq=cbind.data.frame(inlove_uni_count, hateher_uni_count, marchscience_uni_count)
pander(emoji_freq, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:EPopular} Five most popular emoji for each hastags")
# xdate_number=xtable(emoji_freq, caption = "Five most popular emoji for each hastags", label = "tab:EPopular")
# print(xdate_number)
# dat=rbind.data.frame(
#   readRDS("../Data/twitter_inlove.Rds") %>%
#     mutate(tag = "inlove"),
#   readRDS("../Data/twitter_hateher.Rds")%>%
#     mutate(tag = "hateher"),
#   readRDS("../data/twitter_marchscience.Rds") %>%
#     mutate(tag = "marchscience"), stringsAsFactors = F
#   )
dat=rbind.data.frame(
readRDS("../data/twitter_inlove.Rds") %>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "inlove"),
readRDS("../data/twitter_hateher.Rds")%>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "hateher"),
readRDS("../data/twitter_marchscience.Rds") %>%.$V1 %>% paste0(collapse=" "),
stringsAsFactors = F
# mutate(tag = "marchscience"), stringsAsFactors = F
)
names(dat)<-"V1"
dat$V1 %>>%
tolower() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()-> dat1
stop_stem=lapply(dat1, StopNStem) %>%
do.call("rbind",.) %>%
rbind.data.frame(stringsAsFactors=F)
stop_stem$V1 %>%
VectorSource() %>%
VCorpus()%>%
DocumentTermMatrix() ->dtm
lda=LDA(dtm, k = 3, control = list(alpha=1))
lda.raw=terms(lda,10)
pander(lda.raw, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:LDAraw} Output LDA with the raw data")
ap_topics <- tidy(lda, matrix = "beta")
names(ap_topics)[3]<-"phi"
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, phi) %>%
ungroup() %>%
arrange(topic, desc(phi)) #%>%View()
# ap_top_terms<-ap_top_terms[-11,] #Two topic 1 with same phi
split(ap_top_terms, as.factor(ap_top_terms$topic)) %>%
do.call("cbind",.) %>%
select(everything(), -contains("topic")) %>%
pander(split.table = 180, style = 'rmarkdown', caption = "\\label{tab:LDArawp} Word prob. given topic")
dat=rbind.data.frame(
readRDS("../data/twitter_inlove.Rds") %>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "inlove"),
readRDS("../data/twitter_hateher.Rds")%>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "hateher"),
readRDS("../data/twitter_marchscience.Rds") %>%.$V1 %>% paste0(collapse=" "),
stringsAsFactors = F
# mutate(tag = "marchscience"), stringsAsFactors = F
)
names(dat)<-"V1"
dat$V1 %>>%
tolower() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()-> dat1
stop_stem=lapply(dat1, StopNStem) %>%
do.call("rbind",.) %>%
rbind.data.frame(stringsAsFactors=F)
stop_stem$V1 %>%
VectorSource() %>%
VCorpus()%>%
DocumentTermMatrix() ->dtm
lda=LDA(dtm, k = 3, control = list(alpha=1))
lda.raw=terms(lda,10)
pander(lda.raw, split.table = 180, style = 'rmarkdown', caption = "\\label{tab:LDAraw} Output LDA with the raw data")
ap_topics <- tidy(lda, matrix = "beta")
names(ap_topics)[3]<-"phi"
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, phi) %>%
ungroup() %>%
arrange(topic, desc(phi)) #%>%View()
# ap_top_terms<-ap_top_terms[-11,] #Two topic 1 with same phi
split(ap_top_terms, as.factor(ap_top_terms$topic)) %>%
do.call("cbind",.) %>%
select(everything(), -contains("topic")) %>%
pander(split.table = 180, style = 'rmarkdown', caption = "\\label{tab:LDArawp} Word prob. given topic")
source("req.R")
library(ggrepel)
Sys.setlocale('LC_ALL','C')
load("../data/emojidata.rda")
dat=rbind.data.frame(
readRDS("../data/twitter_inlove.Rds") %>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "inlove"),
readRDS("../data/twitter_hateher.Rds")%>% .$V1 %>% paste0(collapse=" "),
# mutate(tag = "hateher"),
readRDS("../data/twitter_marchscience.Rds") %>%.$V1 %>% paste0(collapse=" "),
stringsAsFactors = F
# mutate(tag = "marchscience"), stringsAsFactors = F
)
names(dat)<-"V1"
dat$V1 %>>%
tolower() %>>%
clean_abb() %>>%
cleaning0() %>%
gsub("[[:punct:]]", "", .) %>%
gsub("\"", "", .) %>%
gsub("\\s{2,}", "\\s", .) %>%
trimws()-> dat1
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
pkg=c("tidytext","tidyverse", "pander","topicmodels", "tm", "gridExtra", "pipeR", "ggtern", "tidyr", "png", "grid", "ggrepel")
ipak(pkg)
